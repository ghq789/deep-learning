{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# 导入各类包\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import cv2 as cv \n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np \n",
    "from keras.preprocessing import Image\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数计算图像的Hu矩\n",
    "def calculate_hu_moments(image):\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # 二值化\n",
    "    ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    # 计算Hu矩\n",
    "    moments = cv2.moments(binary)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    # 归一化处理\n",
    "    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + np.finfo(float).eps)\n",
    "    return hu_moments.flatten()\n",
    "\n",
    "def extract_grid_image(image, position):\n",
    "    # 假设九宫格每个模块的大小是原图像的三分之一\n",
    "    height, width = image.shape[:2]\n",
    "    grid_height = height // 3\n",
    "    grid_width = width // 3\n",
    "\n",
    "    # 根据位置提取模块图像\n",
    "    x, y = position\n",
    "    start_x = x * grid_width\n",
    "    start_y = y * grid_height\n",
    "    end_x = start_x + grid_width\n",
    "    end_y = start_y + grid_height\n",
    "\n",
    "    # 确保提取范围在图像尺寸之内\n",
    "    end_x = min(end_x, width)\n",
    "    end_y = min(end_y, height)\n",
    "\n",
    "    # 提取模块图像\n",
    "    grid_image = image[start_y:end_y, start_x:end_x]\n",
    "    return grid_image\n",
    "\n",
    "# 函数定义：从原始图像中提取指定位置的模块图像\n",
    "def extract_grid_image(image, position):\n",
    "    x, y = position\n",
    "    height = image.shape[0] // 3\n",
    "    width = image.shape[1] // 3\n",
    "    return image[y * height:(y + 1) * height, x * width:(x + 1) * width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笔画提取及评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@82.420] global loadsave.cpp:248 findDecoder imread_('E:\\python_files\\pytorch\\myself\\gujiatiqu\\a.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image not found or path is incorrect",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpython_files\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpytorch\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmyself\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mgujiatiqu\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124ma.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage not found or path is incorrect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# 加载参考模块图像\u001B[39;00m\n\u001B[1;32m      7\u001B[0m reference_image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpython_files\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpytorch\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmyself\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mgujiatiqu\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mb.png\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# 替换为你的参考图像路径\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Image not found or path is incorrect"
     ]
    }
   ],
   "source": [
    "# 加载原始图像\n",
    "Image = cv2.imread('E:\\\\python_files\\\\pytorch\\\\myself\\\\gujiatiqu\\\\a.png')\n",
    "if Image is None:\n",
    "    raise ValueError(\"Image not found or path is incorrect\")\n",
    "\n",
    "# 加载参考模块图像\n",
    "reference_image = cv2.imread('E:\\\\python_files\\\\pytorch\\\\myself\\\\gujiatiqu\\\\b.png')  # 替换为你的参考图像路径\n",
    "if reference_image is None:\n",
    "    raise ValueError(\"Reference image not found or path is incorrect\")\n",
    "\n",
    "# 计算参考模块的Hu矩\n",
    "reference_hu_moments = calculate_hu_moments(reference_image)\n",
    "\n",
    "# 定义九宫格的位置和权重\n",
    "grid_positions = [(0, 0), (0, 1), (0, 2),\n",
    "                  (1, 0), (1, 1), (1, 2),\n",
    "                  (2, 0), (2, 1), (2, 2)]\n",
    "\n",
    "grid_weights = [0.1, 0.1, 0.1,\n",
    "                0.1, 0.5, 0.1,\n",
    "                0.1, 0.1, 0.1]\n",
    "\n",
    "# 初始化存储每个模块Hu矩的列表\n",
    "hu_moments_list = []\n",
    "\n",
    "# 遍历九宫格的位置\n",
    "for position in grid_positions:\n",
    "    # 提取当前模块的图像\n",
    "    grid_image = extract_grid_image(Image, position)\n",
    "    # 计算当前模块的Hu矩\n",
    "    hu_moments = calculate_hu_moments(grid_image)\n",
    "    # 将Hu矩添加到列表中\n",
    "    hu_moments_list.append(hu_moments)\n",
    "\n",
    "# 计算皮尔逊相关系数\n",
    "correlation_coefficients = []\n",
    "for hu_moments in hu_moments_list:\n",
    "    correlation_coefficient = np.corrcoef(reference_hu_moments, hu_moments)[0, 1]\n",
    "    correlation_coefficients.append(correlation_coefficient)\n",
    "\n",
    "# 加权求和\n",
    "weighted_sum = np.dot(correlation_coefficients, grid_weights)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Weighted Sum:\", weighted_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "骨架提取及评价\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义方法\n",
    "def VThin(image, array):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    NEXT = 1\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if NEXT == 0:\n",
    "                NEXT = 1\n",
    "            else:\n",
    "                M = image[i, j - 1] + image[i, j] + image[i, j + 1] if 0 < j < w - 1 else 1\n",
    "                if image[i, j] == 0 and M != 0:\n",
    "                    a = [0] * 9\n",
    "                    for k in range(3):\n",
    "                        for l in range(3):\n",
    "                            if -1 < (i - 1 + k) < h and -1 < (j - 1 + l) < w and image[i - 1 + k, j - 1 + l] == 255:\n",
    "                                a[k * 3 + l] = 1\n",
    "                    sum = a[0] * 1 + a[1] * 2 + a[2] * 4 + a[3] * 8 + a[5] * 16 + a[6] * 32 + a[7] * 64 + a[8] * 128\n",
    "                    image[i, j] = array[sum] * 255\n",
    "                    if array[sum] == 1:\n",
    "                        NEXT = 0\n",
    "    return image\n",
    "\n",
    "def HThin(image, array):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    NEXT = 1\n",
    "    for j in range(h):\n",
    "        for i in range(w):\n",
    "            if NEXT == 0:\n",
    "                NEXT = 1\n",
    "            else:\n",
    "                M = image[i - 1, j] + image[i, j] + image[i + 1, j] if 0 < i < h - 1 else 1\n",
    "                if image[i, j] == 0 and M != 0:\n",
    "                    a = [0] * 9\n",
    "                    for k in range(3):\n",
    "                        for l in range(3):\n",
    "                            if -1 < (i - 1 + k) < h and -1 < (j - 1 + l) < w and image[i - 1 + k, j - 1 + l] == 255:\n",
    "                                a[k * 3 + l] = 1\n",
    "                    sum = a[0] * 1 + a[1] * 2 + a[2] * 4 + a[3] * 8 + a[5] * 16 + a[6] * 32 + a[7] * 64 + a[8] * 128\n",
    "                    image[i, j] = array[sum] * 255\n",
    "                    if array[sum] == 1:\n",
    "                        NEXT = 0\n",
    "    return image\n",
    "\n",
    "def Xihua(image, array, num=20):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    iXihua = np.zeros((w, h, 1), dtype=np.uint8)\n",
    "    np.copyto(iXihua, image)\n",
    "    for i in range(num):\n",
    "        VThin(iXihua, array)\n",
    "        HThin(iXihua, array)\n",
    "    return iXihua\n",
    "\n",
    "def Two(image):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "\n",
    "    iTwo = np.zeros((w, h, 1), dtype=np.uint8)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            iTwo[i, j] = 0 if image[i, j] < 200 else 255\n",
    "    return iTwo\n",
    "\n",
    "# 加载图片并预处理\n",
    "def load_and_process_image(img_path):\n",
    "    img = Image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = Image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_array, axis=0)\n",
    "    img_tensor = preprocess_input(img_tensor)\n",
    "    return img_tensor\n",
    "\n",
    "# 提取特征\n",
    "def extract_features(model, img_path):\n",
    "    img_tensor = load_and_process_image(img_path)\n",
    "    features = model.predict(img_tensor)\n",
    "    # 将特征扁平化为一维数组\n",
    "    flattened_features = features.flatten()\n",
    "    return flattened_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mVGG16\u001B[49m(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m'\u001B[39m, include_top\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m dataUrl \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# 图片路径\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'VGG16' is not defined"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "dataUrl = 'data'\n",
    "\n",
    "# 图片路径\n",
    "img_path1 = '{dataUrl}\\Template_pictures\\\\1.png'\n",
    "img_path2 = '{dataUrl}\\Handcopied_pictures\\\\2.png'\n",
    "img_path3 = '{dataUrl}\\Handcopied_pictures\\\\3.png'\n",
    "\n",
    "array = [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, \\\n",
    "         0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, \\\n",
    "         1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, \\\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, \\\n",
    "         0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "         1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, \\\n",
    "         1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "# 提取特征向量\n",
    "vector1 = np.array(extract_features(model, img_path1)).reshape(1, 25088)\n",
    "vector2 = np.array(extract_features(model, img_path3)).reshape(1, 25088)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# vector1 = np.array(extract_features(model, img_path1))\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# vector2 = extract_features(model, img_path3)\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m normalized_distance \u001B[38;5;241m=\u001B[39m cosine_similarity(\u001B[43mvector1\u001B[49m, vector2)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe Euclidean distance between vector1 and vector2 is: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnormalized_distance\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m image \u001B[38;5;241m=\u001B[39m cv\u001B[38;5;241m.\u001B[39mimread(img_path1, \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'vector1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# vector1 = np.array(extract_features(model, img_path1))\n",
    "# vector2 = extract_features(model, img_path3)\n",
    "normalized_distance = cosine_similarity(vector1, vector2)\n",
    "print(f\"The Euclidean distance between vector1 and vector2 is: {normalized_distance}\")\n",
    "\n",
    "\n",
    "Image = cv.imread(img_path1, 0)\n",
    "iTwo = Two(Image)\n",
    "iThin = Xihua(iTwo, array)\n",
    "# cv.imshow('image', image)\n",
    "# cv.imshow('iTwo', iTwo)\n",
    "cv.imshow('iThin', iThin)\n",
    "\n",
    "image1 = cv.imread(img_path2, 0)\n",
    "iTwo1 = Two(image1)\n",
    "iThin1 = Xihua(iTwo1, array)\n",
    "cv.imshow('iThin1', iThin1)\n",
    "\n",
    "\n",
    "cv.imwrite('{dataUrl}\\output\\a.png',iThin)\n",
    "cv.imwrite('{dataUrl}\\output\\b.png',iThin1)\n",
    "cv.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
